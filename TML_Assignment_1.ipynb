{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "na5qXIMnPBPB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "\n",
        "\n",
        "import requests\n",
        "from typing import Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Sommer25/TML/Assignment_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyzaK5KmPvTY",
        "outputId": "349f163b-3813-49fb-d0fc-b861b46fb91d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Sommer25/TML/Assignment_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Constants ---\n",
        "mean = [0.2980, 0.2962, 0.2987]\n",
        "std = [0.2886, 0.2875, 0.2889]\n",
        "BATCH_SIZE = 64\n",
        "TOKEN = \"55172888\"  # <-- Replace this with your actual token\n",
        "\n",
        "# --- Dataset Classes ---\n",
        "class TaskDataset(Dataset):\n",
        "    def __init__(self, transform=None):\n",
        "        self.ids = []\n",
        "        self.imgs = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
        "        id_ = self.ids[index]\n",
        "        img = self.imgs[index]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[index]\n",
        "        return id_, img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "class MembershipDataset(TaskDataset):\n",
        "    def __init__(self, transform=None):\n",
        "        super().__init__(transform)\n",
        "        self.membership = []\n",
        "\n",
        "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int, int]:\n",
        "        id_, img, label = super().__getitem__(index)\n",
        "        return id_, img, label, self.membership[index]\n",
        "\n",
        "# --- Load the ResNet18 Target Model ---\n",
        "model = resnet18(pretrained=False)\n",
        "model.fc = torch.nn.Linear(512, 44)\n",
        "ckpt = torch.load(\"./01_MIA.pt\", map_location=\"cpu\")\n",
        "model.load_state_dict(ckpt)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),           # Convert tensor to PIL image\n",
        "    transforms.ToTensor(),            # Convert back to tensor (as float in [0,1])\n",
        "    transforms.Normalize(mean, std),  # Normalize using provided mean/std\n",
        "])\n",
        "\n",
        "# Load the public dataset\n",
        "public_data: MembershipDataset = torch.load(\"pub.pt\", weights_only = False)\n",
        "public_data.transform = transform\n",
        "public_loader = DataLoader(public_data, batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mntO55FdPFy7",
        "outputId": "02682cce-e918-4d6b-f4ab-8797e2322835"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(public_loader),len(public_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sp-EkwV7Mju",
        "outputId": "d3113c94-cbaa-4b42-c8ae-e69b4bfe0901"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(313, 20000)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "public_data[0][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aorbycOp7QT3",
        "outputId": "6ae5a87b-b69d-4e7e-976b-bf236d0fd505"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract features for attack training"
      ],
      "metadata": {
        "id": "44mIb1PWPne-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction_entropy(probs):\n",
        "    return -torch.sum(probs * torch.log(probs + 1e-10), dim=1)\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for ids, imgs, true_labels, memberships in tqdm(public_loader):\n",
        "        outputs = model(imgs)  # logits\n",
        "        probs = F.softmax(outputs, dim=1)  # probabilities\n",
        "        ent = prediction_entropy(probs).cpu().numpy().reshape(-1,1)\n",
        "        probs_np = probs.cpu().numpy()  # shape (batch, 44)\n",
        "\n",
        "        # Cross entropy loss per sample\n",
        "        true_labels_tensor = true_labels.long()\n",
        "        losses = F.cross_entropy(outputs, true_labels_tensor, reduction='none').cpu().numpy().reshape(-1,1)\n",
        "\n",
        "        # Combine features: probs + entropy + loss\n",
        "        batch_features = np.hstack([probs_np, ent, losses])\n",
        "        features.append(batch_features)\n",
        "        labels.append(memberships.numpy())\n",
        "\n",
        "features = np.vstack(features)\n",
        "labels = np.hstack(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDrcEPlIPNBY",
        "outputId": "3ef660bc-5bfa-410e-bf93-d9e0e46fb5d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [00:41<00:00,  7.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Attacker Model"
      ],
      "metadata": {
        "id": "B_tnrdOPPjQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=100, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "val_preds = mlp.predict_proba(X_val)[:,1]\n",
        "\n",
        "auc = roc_auc_score(y_val, val_preds)\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "255O8B7OPZSA",
        "outputId": "da60360c-25e6-4076-f714-e5d722b07772"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.6583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jznyFI8G8lmD",
        "outputId": "06c0ee03-501e-4ca4-e104-ea7f794302c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "models = {\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(128, 64, 32),\n",
        "                         max_iter=500,\n",
        "                         learning_rate_init=0.001,\n",
        "                         early_stopping=True,\n",
        "                         random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(n_estimators=300,\n",
        "                             learning_rate=0.05,\n",
        "                             max_depth=4,\n",
        "                             subsample=0.8,\n",
        "                             colsample_bytree=0.8,\n",
        "                             use_label_encoder=False,\n",
        "                             eval_metric='logloss',\n",
        "                             random_state=42),\n",
        "    \"CatBoost\": CatBoostClassifier(iterations=500,\n",
        "                                   learning_rate=0.03,\n",
        "                                   depth=6,\n",
        "                                   od_type='Iter',\n",
        "                                   od_wait=20,\n",
        "                                   verbose=0,\n",
        "                                   random_seed=42),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=200,\n",
        "                                   learning_rate=1.0,\n",
        "                                   random_state=42)\n",
        "}\n",
        "\n",
        "# Train, Predict, Evaluate\n",
        "results = {}\n",
        "for name, attack_model in models.items():\n",
        "    attack_model.fit(X_train, y_train)\n",
        "    y_probs = attack_model.predict_proba(X_val)[:, 1]\n",
        "    auc = roc_auc_score(y_val, y_probs)\n",
        "    results[name] = auc\n",
        "    print(f\"{name} ROC-AUC: {auc:.4f}\")\n",
        "\n",
        "# Select Best Model\n",
        "best_model = max(results, key=results.get)\n",
        "print(f\"\\n✅ Best model: {best_model} with AUC = {results[best_model]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wnf9nd4e8bIf",
        "outputId": "51aadb07-17d9-4be8-951f-112104d86630"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP ROC-AUC: 0.6474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:04:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost ROC-AUC: 0.6613\n",
            "CatBoost ROC-AUC: 0.6645\n",
            "AdaBoost ROC-AUC: 0.6440\n",
            "\n",
            "✅ Best model: CatBoost with AUC = 0.6645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict membership scores on private dataset"
      ],
      "metadata": {
        "id": "M98jLMkD4-cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2L9YM5H_5pE8",
        "outputId": "bf04fe0c-a540-4dbc-de75-14653cc70ea8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CatBoost'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load Private Dataset ---\n",
        "priv_data: MembershipDataset = torch.load(\"priv_out.pt\", weights_only = False)\n",
        "priv_features = []\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(len(priv_data))):\n",
        "        sample = priv_data[i]\n",
        "        # Unpack only the needed parts\n",
        "        if len(sample) >= 3:\n",
        "            ids, img, label = sample[:3]\n",
        "        else:\n",
        "            continue  # skip malformed sample\n",
        "        img = img.unsqueeze(0)  # Add batch dim\n",
        "        label = torch.tensor([label])\n",
        "        outputs = model(img)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        ent = prediction_entropy(probs).cpu().numpy().reshape(-1, 1)\n",
        "        probs_np = probs.cpu().numpy()\n",
        "        losses = F.cross_entropy(outputs, label.long(), reduction='none').cpu().numpy().reshape(-1, 1)\n",
        "\n",
        "        batch_features = np.hstack([probs_np, ent, losses])\n",
        "        priv_features.append(batch_features)\n",
        "\n",
        "priv_features = np.vstack(priv_features)\n",
        "\n",
        "# Predict membership scores\n",
        "# membership_scores = mlp.predict_proba(priv_features)[:, 1]\n",
        "# membership_scores = models[best_model].predict_proba(priv_features)[:, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDdF2lVm7Igk",
        "outputId": "126d360a-6977-4179-f4ce-54f26d3f4aea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20000/20000 [02:58<00:00, 112.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "membership_scores = models[best_model].predict_proba(priv_features)[:, 1]"
      ],
      "metadata": {
        "id": "G1idwmxHPrGX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "membership_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lztrSGmlPu2E",
        "outputId": "2b96c9b2-6cdb-463c-9398-12a7b4e52803"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.54454371, 0.55492939, 0.0325212 , ..., 0.3607481 , 0.49960944,\n",
              "       0.56055112])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare submission CSV\n"
      ],
      "metadata": {
        "id": "CiexrzllPe4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\n",
        "    \"ids\": priv_data.ids,\n",
        "    \"score\": membership_scores,\n",
        "})\n",
        "\n",
        "df.to_csv(\"test.csv\", index=False)\n",
        "response = requests.post(\n",
        "    \"http://34.122.51.94:9090/mia\",\n",
        "    files={\"file\": open(\"test.csv\", \"rb\")},\n",
        "    headers={\"token\": TOKEN}\n",
        ")\n",
        "print(response.json())"
      ],
      "metadata": {
        "id": "Dyt_uX45PdZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96566595-6e29-4129-89dd-2f938905b255"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'TPR@FPR=0.05': 0.13133333333333333, 'AUC': 0.6665335555555555}\n"
          ]
        }
      ]
    }
  ]
}